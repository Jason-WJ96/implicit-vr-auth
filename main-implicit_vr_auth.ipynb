{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a34089e-7475-417f-967e-6c1e2a0cd0cc",
   "metadata": {},
   "source": [
    "# **Package import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e54f2-3238-448a-ab4b-f0986af15602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "import joblib\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876c6a9a-fdee-4d12-a41e-04715974112d",
   "metadata": {},
   "source": [
    "## VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce37311-34aa-4cdb-ac3b-5eea1f39280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hid_dim_1, hid_dim_2, latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hid_dim_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim_1, hid_dim_2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu = nn.Linear(hid_dim_2, latent_dim)  \n",
    "        self.log_var = nn.Linear(hid_dim_2, latent_dim)  \n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hid_dim_2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim_2, hid_dim_1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hid_dim_1, input_dim),\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std).to(device)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        mu = self.mu(encoded)\n",
    "        log_var = self.log_var(encoded)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        decoded = self.decoder(z)\n",
    "        return decoded, mu, log_var\n",
    "\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    recon_loss = nn.MSELoss()(recon_x, x)\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return recon_loss + kl_loss\n",
    "\n",
    "def generate_new_data(vae_model, latent_dim, num_samples=100):\n",
    "    vae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)  \n",
    "        generated_data = vae_model.decoder(z)\n",
    "        return generated_data.cpu().numpy()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d1a0f-1791-4931-8961-4c4366f8a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "print(f\"Current path: {current_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e42a9-9226-4dfb-8200-9e6f4f242726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference users group list\n",
    "basegroup_list = ['P21', 'P22', 'P23', 'P24'] #  4th, 10th, 16th, 22th\n",
    "subgroup1_list = ['P22', 'P23', 'P24']  \n",
    "subgroup2_list = ['P21', 'P23', 'P24']  \n",
    "subgroup3_list = ['P21', 'P22', 'P24']  \n",
    "subgroup4_list = ['P21', 'P22', 'P23'] \n",
    "\n",
    "# Path where the feature dataframe is saved\n",
    "feature_path = os.path.join(current_path, 'feature_data_csv(24)')\n",
    "    \n",
    "with open(os.path.join(feature_path, 'Feature_category.yaml'),'r') as f:\n",
    "    feature_cat=yaml.full_load(f)\n",
    "\n",
    "# Path to save the trained model \n",
    "os.makedirs(os.path.join(current_path, 'Trainined_model'), exist_ok=True)\n",
    "\n",
    "# Path for saving result\n",
    "save_folder = 'Result-EER'\n",
    "os.makedirs(os.path.join(current_path, save_folder), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef1c746-d774-497a-9edb-fb2979a73922",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7302b3-39b4-491d-80ab-9e4074ec63c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the desired tasks to the list below\n",
    "task_list = [\n",
    "    'grabbing',\n",
    "    'pointing', \n",
    "    'typing'\n",
    "] \n",
    "\n",
    "# Add the desired training scenarios to the list below\n",
    "scenario_list = [\n",
    "    'Scen1', \n",
    "    'Scen2'\n",
    "]  \n",
    "\n",
    "# Add the desired classifier models to the list below\n",
    "model_list = {\n",
    "    'RF': RandomForestClassifier(random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'LR': LogisticRegression(random_state=42),\n",
    "    # 'GradientBoost': GradientBoostingClassifier(random_state=42),\n",
    "    # 'DecisionTree': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Add the desired reference user groups to the list below\n",
    "ref_list = {\n",
    "    'BaseGroup': basegroup_list,\n",
    "    # 'SubGroup1': subgroup1_list,\n",
    "    # 'SubGroup2': subgroup2_list,\n",
    "    # 'SubGroup3': subgroup3_list,\n",
    "    # 'SubGroup4': subgroup4_list,\n",
    "}\n",
    "\n",
    "# Add the desired data augmentation techniques to the list below\n",
    "data_aug_list = [\n",
    "    'NoAug',\n",
    "    # 'SMOTE', \n",
    "    # 'VAE'             \n",
    "] \n",
    "\n",
    "# Add the desired feature categories to the list below\n",
    "feature_category_list = [\n",
    "    'movement',\n",
    "    'spatial', \n",
    "    'orientation', \n",
    "    'interaction'\n",
    "] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a2b881-90c7-4a4a-be9f-6b4974019d31",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab5ed0-20a3-4de7-ae9f-49c546e123a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = [feat for cate in feature_category_list for feat in feature_cat[cate]]\n",
    "all_result_col = ['Model', 'Train_study', 'Referenec_set', 'Aug']\n",
    "all_result_col += [f\"{t}_{s}\" for s in [\"median\", \"iqr\"] for t in task_list]\n",
    "all_df = pd.DataFrame([], columns = all_result_col)\n",
    "\n",
    "for train_study in scenario_list:\n",
    "    print(f\"\\n[[Train Study: {train_study}]]\"); \n",
    "    for m_name, model in model_list.items():\n",
    "        print(f\"Binary Model [{m_name}]\");     \n",
    "        for ref_name, ref in ref_list.items(): \n",
    "            print(f\"  [{ref_name}]\");                 \n",
    "            for aug in data_aug_list: \n",
    "                print(f\"  ------ {aug} ------\"); \n",
    "            \n",
    "                result_column = ['Task', 'Name', 'EER']\n",
    "                result_df = pd.DataFrame([], columns = result_column)\n",
    "            \n",
    "                for task in task_list:\n",
    "                    Dataframe_all = pd.read_csv(os.path.join(f\"{feature_path}\", f\"{task}_Dataframe_all.csv\"))\n",
    "                    all_user_list = Dataframe_all['Name'].unique().tolist()  \n",
    "            \n",
    "                    reference_df = Dataframe_all[Dataframe_all[\"Name\"].isin(ref)]\n",
    "                    Dataframe_Users = Dataframe_all[~Dataframe_all[\"Name\"].isin(basegroup_list)]    \n",
    "                    user_list = [u for u in all_user_list if u not in basegroup_list]\n",
    "            \n",
    "                    for user in user_list:              \n",
    "                        # (0) ========== Data Preparation ==========\n",
    "                        if train_study == \"Scen1\":\n",
    "                            train_normal_df = Dataframe_Users[(Dataframe_Users[\"Name\"]==user)&(Dataframe_Users[\"Study\"]==\"Study1\")]                    \n",
    "                            test_normal_df = Dataframe_Users[(Dataframe_Users[\"Name\"]==user)&(Dataframe_Users[\"Study\"]!=\"Study1\")]    \n",
    "                            test_illegal_df = Dataframe_Users[(Dataframe_Users[\"Name\"]!=user)&(Dataframe_Users[\"Study\"]!=\"Study1\")]      \n",
    "                        elif train_study == \"Scen2\":                    \n",
    "                            train_normal_df = Dataframe_Users[(Dataframe_Users[\"Name\"]==user)&(Dataframe_Users[\"Study\"]!=\"Study3\")]                    \n",
    "                            test_normal_df = Dataframe_Users[(Dataframe_Users[\"Name\"]==user)&(Dataframe_Users[\"Study\"]==\"Study3\")]    \n",
    "                            test_illegal_df = Dataframe_Users[(Dataframe_Users[\"Name\"]!=user)&(Dataframe_Users[\"Study\"]==\"Study3\")]    \n",
    "                        else:\n",
    "                            train_normal_df = pd.DataFrame([])  \n",
    "                            test_normal_df = pd.DataFrame([]) \n",
    "                            test_illegal_df = pd.DataFrame([]) \n",
    "\n",
    "                        # (1) ========== Data Augmentation ==========\n",
    "                        if aug == \"VAE\":\n",
    "                            vae_train_u_np = train_normal_df[feature_list].to_numpy()\n",
    "                            vae_train_u_tensor = torch.FloatTensor(vae_train_u_np).to(device)\n",
    "                            input_dim = vae_train_u_tensor.shape[1]\n",
    "        \n",
    "                            vae = VAE(input_dim = input_dim, hid_dim_1 = 128, hid_dim_2 = 64, latent_dim =  16).to(device)\n",
    "                            optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "        \n",
    "                            epochs = 1000\n",
    "                            for epoch in range(epochs):\n",
    "                                optimizer.zero_grad()\n",
    "                                reconstructed, mu, log_var = vae(vae_train_u_tensor)\n",
    "                                loss = loss_function(reconstructed, vae_train_u_tensor, mu, log_var)\n",
    "                                loss.backward()\n",
    "                                optimizer.step()\n",
    "                                \n",
    "                            generated_u_data = generate_new_data(vae, latent_dim = 16, num_samples=330)\n",
    "                            generated_normal_df = pd.DataFrame(generated_u_data, columns = feature_list)\n",
    "                            train_normal_df = pd.concat([train_normal_df[feature_list], generated_normal_df], ignore_index = True)                        \n",
    "                            \n",
    "                        elif aug == \"SMOTE\":\n",
    "                            X_smote_t = train_normal_df[feature_list]\n",
    "                            y_smote_t = pd.Series([True] * len(X_smote_t))\n",
    "                            X_smote_f = reference_df[feature_list]\n",
    "                            y_smote_f = pd.Series([False] * len(X_smote_f))\n",
    "                            X_smote = pd.concat([X_smote_t, X_smote_f], ignore_index=True)\n",
    "                            y_smote = pd.concat([y_smote_t, y_smote_f], ignore_index=True) \n",
    "        \n",
    "                            smote = SMOTE(random_state=42)\n",
    "                            X_resampled, y_resampled = smote.fit_resample(X_smote, y_smote)\n",
    "        \n",
    "                            X_resampled_df = pd.DataFrame(X_resampled, columns=feature_list)\n",
    "                            y_resampled_df = pd.DataFrame(y_resampled, columns=['label'])\n",
    "                            resampled_df = pd.concat([X_resampled_df, y_resampled_df], axis=1)    \n",
    "                            train_normal_df = resampled_df[resampled_df[\"label\"]==True] \n",
    "                            \n",
    "                        elif aug == \"NoAug\":\n",
    "                            pass\n",
    "                            \n",
    "                        else:\n",
    "                            print(\"Wrong Command\")\n",
    "        \n",
    "                        # (3) ========== Training Binary Classifier Model ==========\n",
    "                        X_train_t = train_normal_df[feature_list]\n",
    "                        y_train_t = pd.Series([True] * len(X_train_t))\n",
    "                        X_train_f = reference_df[feature_list]\n",
    "                        y_train_f = pd.Series([False] * len(X_train_f))\n",
    "                        X_train = pd.concat([X_train_t, X_train_f], ignore_index=True)\n",
    "                        y_train = pd.concat([y_train_t, y_train_f], ignore_index=True) \n",
    "                        \n",
    "                        stdscaler = StandardScaler()\n",
    "                        X_train = stdscaler.fit_transform(X_train)                    \n",
    "                        model.fit(X_train, y_train)     \n",
    "                        \n",
    "                        joblib.dump(model, os.path.join(current_path, \"Trainined_model\", f\"{m_name}_{task}_{user}_{ref_name}_{aug}_{train_study}.pkl\"))\n",
    "        \n",
    "                        # (4) ========== Testing Binary Classifier Model ========== \n",
    "                        X_test_t = test_normal_df[feature_list]\n",
    "                        y_test_t = pd.Series([True] * len(X_test_t))\n",
    "                        X_test_f = test_illegal_df[feature_list]\n",
    "                        y_test_f = pd.Series([False] * len(X_test_f))\n",
    "                        X_test = pd.concat([X_test_t, X_test_f], ignore_index=True)\n",
    "                        y_test = pd.concat([y_test_t, y_test_f], ignore_index=True) \n",
    "                        \n",
    "                        X_test = stdscaler.transform(X_test)\n",
    "                        y_test = y_test.values.ravel()\n",
    "                        \n",
    "                        y_test_pred = model.predict(X_test)\n",
    "                        y_test_prob = model.predict_proba(X_test)[:, 1] \n",
    "        \n",
    "                        fpr, tpr, thresholds = roc_curve(y_test, y_test_prob)\n",
    "                        roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "                        far = fpr\n",
    "                        frr = 1 - tpr      \n",
    "                        eer = far[np.nanargmin(np.abs(far - frr))]                                   \n",
    "        \n",
    "                        new_df = pd.DataFrame([[task, user, round(eer ,4)]], columns = result_column)\n",
    "                        result_df = pd.concat([result_df, new_df], ignore_index = True)\n",
    "                            \n",
    "                median_eer = round(result_df.groupby('Task')['EER'].median(), 4)\n",
    "                iqr_eer = result_df.groupby('Task')['EER'].apply(lambda x: round(np.percentile(x, 75) - np.percentile(x, 25), 4))     \n",
    "                for t_name in result_df['Task'].unique().tolist():\n",
    "                    print(f\"    {t_name:<8} median EER: {median_eer[t_name]:.4f} | IQR: {iqr_eer[t_name]:.4f}\")\n",
    "    \n",
    "                all_res_list = [m_name, train_study, ref_name, aug] \n",
    "                all_res_list += [value for t in task_list for value in [median_eer[t], iqr_eer[t]]]\n",
    "                \n",
    "                all_add_df = pd.DataFrame([all_res_list], columns = all_result_col)\n",
    "                all_df = pd.concat([all_df, all_add_df], ignore_index = True)                \n",
    "                result_df.to_csv(os.path.join(save_folder, f\"Result-{m_name}-{ref_name}-{aug}-{train_study}.csv\"), index=False)\n",
    "all_df.to_csv(os.path.join(save_folder, f\"All-Result.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
